# -*- coding: utf-8 -*-
"""EFC4 (3).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10cSUtVsL5JRUWciW9vX6JiFq4idmDRTO
"""

import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
from torch.autograd import grad
import pandas as pd
import os
from sklearn.metrics import r2_score
from scipy.interpolate import interp1d
from torch.utils.data import TensorDataset, DataLoader
from tqdm.auto import tqdm
import time

# Check if GPU is available
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

# Physical parameters (unchanged)
D = 5.0
De = 0.01
A = 0.5
epsilon = 0.01
psi = 0.01

# Neural network (unchanged)
class PINN(nn.Module):
    def __init__(self, layers=5, neurons=64):
        super().__init__()
        
        # Build the network with configurable architecture
        layers_list = []
        layers_list.append(nn.Linear(1, neurons))
        layers_list.append(nn.Tanh())
        
        for _ in range(layers - 1):
            layers_list.append(nn.Linear(neurons, neurons))
            layers_list.append(nn.Tanh())
            
        layers_list.append(nn.Linear(neurons, 6))
        
        self.net = nn.Sequential(*layers_list)
        self.E = nn.Parameter(torch.tensor(1.0))
        
        # Initialize weights
        for layer in self.net:
            if isinstance(layer, nn.Linear):
                nn.init.xavier_normal_(layer.weight)
                nn.init.constant_(layer.bias, 0.01)

    def forward(self, x):
        return self.net(x)

# Loss function (return components)
def compute_loss(model, x_coll, x_bc0, x_bc1, loss_weights=None):
    # Default loss weights if not provided
    if loss_weights is None:
        loss_weights = {
            'pde': 1.0,
            'bc': 1.0,
            'grad': 0.001
        }
    # Ensure all inputs are on the same device as the model
    device = next(model.parameters()).device
    x_coll = x_coll.to(device)
    x_bc0 = x_bc0.to(device)
    x_bc1 = x_bc1.to(device)
    outputs = model(x_coll)
    u, L, e, tau_xx, tau_yy, tau_zz = torch.split(outputs, 1, dim=1)

    grad_u = grad(u, x_coll, grad_outputs=torch.ones_like(u), create_graph=True)[0]
    grad_L = grad(L, x_coll, grad_outputs=torch.ones_like(L), create_graph=True)[0]
    grad_e = grad(e, x_coll, grad_outputs=torch.ones_like(e), create_graph=True)[0]
    grad_tau_xx = grad(tau_xx, x_coll, grad_outputs=torch.ones_like(tau_xx), create_graph=True)[0]
    grad_tau_yy = grad(tau_yy, x_coll, grad_outputs=torch.ones_like(tau_yy), create_graph=True)[0]
    grad_tau_zz = grad(tau_zz, x_coll, grad_outputs=torch.ones_like(tau_zz), create_graph=True)[0]

    # Governing equations
    residual1 = e * L * u - 1.0
    residual2 = (tau_xx - tau_zz) - u
    E = model.E + 1e-8
    trace_stress = tau_xx + tau_yy + tau_zz
    exp_term = (De * epsilon / E) * trace_stress
    exp_term = torch.clamp(exp_term, -50, 50)
    denominator = torch.clamp(tau_xx - tau_zz, min=1e-8)
    ratio = (tau_yy - tau_zz) / denominator
    ratio = torch.clamp(ratio, min=1e-8)
    residual3 = grad_L + A * torch.sqrt(ratio)
    residual4_xx = (De * u * grad_tau_xx + grad_u * (-2 * tau_xx * De + 4 * psi * De * tau_xx - 2*E)
                   + tau_xx * torch.exp(exp_term))
    residual4_yy = (De * u * grad_tau_yy + grad_L * (-2 * tau_yy * De * u / L + 4 * psi * De * tau_yy / L - 2 * E * u / L)
                   + tau_yy * torch.exp(exp_term))
    residual4_zz = (De * u * grad_tau_zz + grad_e * (-2 * tau_zz * De * u / e + 4 * psi * De * tau_zz / e - 2 * E * u / e)
                   + tau_zz * torch.exp(exp_term))

    # Boundary conditions
    outputs_bc0 = model(x_bc0)
    u0, L0, e0, tau_xx0, tau_yy0, tau_zz0 = torch.split(outputs_bc0, 1, dim=1)
    bc_loss = ((u0 - 1.0)**2 + (L0 - 1.0)**2 + (e0 - 1.0)**2 +
               (tau_xx0 - 1.0)**2 + (tau_yy0 - 0.5)**2 + (tau_zz0 - 0.0)**2).mean()
    outputs_bc1 = model(x_bc1)
    u1 = outputs_bc1[:, 0:1]
    bc_loss = bc_loss + ((u1 - D)**2).mean()

    # Gradient penalty
    grad_penalty = (grad_u.pow(2).mean() + grad_L.pow(2).mean() + grad_e.pow(2).mean() +
                    grad_tau_xx.pow(2).mean() + grad_tau_yy.pow(2).mean() + grad_tau_zz.pow(2).mean())

    # PDE loss
    pde_loss = (residual1.pow(2).mean() + residual2.pow(2).mean() + residual3.pow(2).mean() +
                residual4_xx.pow(2).mean() + residual4_yy.pow(2).mean() + residual4_zz.pow(2).mean())

    # Total loss with weighted components
    total_loss = loss_weights['pde'] * pde_loss + loss_weights['bc'] * bc_loss + loss_weights['grad'] * grad_penalty

    return total_loss, pde_loss, bc_loss, grad_penalty

# Training setup
def generate_points(num_points=10000):
    # Generate a larger pool of collocation points for mini-batch training
    x_coll_all = torch.exp(torch.linspace(np.log(0.001), np.log(1.0), num_points)).reshape(-1, 1)
    x_coll_all.requires_grad_(True)
    x_bc0 = torch.zeros(1, 1, requires_grad=True)
    x_bc1 = torch.ones(1, 1, requires_grad=True)
    # Note: We'll move these to the device later in the training function
    return x_coll_all, x_bc0, x_bc1

# Function to train a model with a specific seed and hyperparameters
def train_model(seed=1234, layers=5, neurons=64, loss_weights=None, max_epochs=30000, batch_size=512, lr=0.001, use_lbfgs=True, 
              patience_adam=1000, patience_lbfgs=5, min_delta=1e-6, num_points=5000):
    # Set random seed for reproducibility
    torch.manual_seed(seed)
    np.random.seed(seed)
    
    # Create model with specified architecture
    model = PINN(layers=layers, neurons=neurons)
    model = model.to(device)  # Move model to GPU if available
    
    # Generate points
    x_coll_all, x_bc0, x_bc1 = generate_points(num_points=num_points)
    
    # Move boundary condition tensors to device
    x_bc0 = x_bc0.to(device)
    x_bc1 = x_bc1.to(device)
    
    # We'll detach x_coll_all here since the DataLoader will lose the requires_grad info
    # We'll set requires_grad=True for each batch during training
    x_coll_tensor = x_coll_all.detach().clone().to(device)  # Ensure tensor is on the correct device
    
    # Create DataLoader for mini-batch training
    dataset = TensorDataset(x_coll_tensor)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
    
    # Adam optimizer
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)
    
    # Training history
    history = {
        'total_loss': [],
        'pde_loss': [],
        'bc_loss': [],
        'grad_penalty': [],
        'E_value': [],
        'unweighted_loss': []
    }
    
    # Training metrics for plotting
    train_losses = []
    epochs = []
    times = []
    start_time = time.time()
    
    # Early stopping variables
    best_loss = float('inf')
    best_model_state = None
    patience_counter = 0
    
    # Create progress bar for epochs
    pbar = tqdm(range(max_epochs), desc=f"Training (seed={seed})")
    
    # Adam training loop
    for epoch in pbar:
        epoch_losses = []
        
        # Inner loop over mini-batches
        for batch_idx, (x_coll_batch,) in enumerate(dataloader):
            optimizer.zero_grad()
            
            # Move batch to device and ensure gradients are tracked
            x_coll_batch = x_coll_batch.to(device).requires_grad_(True)
            
            # Compute loss
            total_loss, pde_loss, bc_loss, grad_penalty = compute_loss(model, x_coll_batch, x_bc0, x_bc1, loss_weights)
            
            # Backpropagation
            total_loss.backward()
            
            # Gradient clipping
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            # Update parameters
            optimizer.step()
            
            epoch_losses.append(total_loss.item())
        
        # Update progress bar with current loss
        avg_epoch_loss = sum(epoch_losses) / len(epoch_losses)
        elapsed = time.time() - start_time
        pbar.set_postfix({
            'loss': f"{avg_epoch_loss:.2e}", 
            'E': f"{model.E.item():.4f}",
            'time': f"{elapsed:.1f}s"
        })
        
        # Calculate average loss for the epoch
        avg_loss = sum(epoch_losses) / len(epoch_losses)
        
        # Early stopping check
        if avg_loss < best_loss - min_delta:
            best_loss = avg_loss
            best_model_state = model.state_dict().copy()
            patience_counter = 0
        else:
            patience_counter += 1
            
        # Check if we should stop training
        if patience_counter >= patience_adam:
            print(f"Early stopping triggered after {epoch} epochs. No improvement for {patience_adam} epochs.")
            # Restore best model
            if best_model_state is not None:
                model.load_state_dict(best_model_state)
            break
        
        # Step the scheduler every 1000 epochs
        if epoch % 1000 == 0:
            scheduler.step()
            
            # Evaluate on the full dataset for logging
            # We need to track gradients for PDE residuals, but don't want to update the model
            model.eval()  # Set model to evaluation mode
            with torch.set_grad_enabled(True):
                # Make sure all inputs have requires_grad=True and are on the right device
                x_coll_eval = x_coll_all.detach().clone().to(device).requires_grad_(True)
                x_bc0_eval = x_bc0.detach().clone().requires_grad_(True)
                x_bc1_eval = x_bc1.detach().clone().requires_grad_(True)
                
                full_total_loss, full_pde_loss, full_bc_loss, full_grad_penalty = compute_loss(
                    model, x_coll_eval, x_bc0_eval, x_bc1_eval, loss_weights)
            model.train()  # Set model back to training mode
            
            # Store metrics for history and plotting
            current_time = time.time() - start_time
            history['total_loss'].append(full_total_loss.item())
            history['pde_loss'].append(full_pde_loss.item())
            history['bc_loss'].append(full_bc_loss.item())
            history['grad_penalty'].append(full_grad_penalty.item())
            history['E_value'].append(model.E.item())
            history['unweighted_loss'].append(full_pde_loss.item() + full_bc_loss.item() + full_grad_penalty.item())
            
            # Also store for plotting
            train_losses.append(full_total_loss.item())
            epochs.append(epoch)
            times.append(current_time)
            
            # No need to print here as tqdm shows the info
    
    # L-BFGS fine-tuning (if enabled)
    if use_lbfgs:
        print("Starting L-BFGS optimization...")
        lbfgs_start_time = time.time()
        
        # Reset early stopping variables for L-BFGS
        best_loss_lbfgs = float('inf')
        best_model_state_lbfgs = model.state_dict().copy()
        patience_counter_lbfgs = 0
        
        # Define closure function for L-BFGS
        def closure():
            optimizer_lbfgs.zero_grad()
            # Create fresh copies with requires_grad=True and on the right device
            x_coll_lbfgs = x_coll_all.detach().clone().to(device).requires_grad_(True)
            x_bc0_lbfgs = x_bc0.detach().clone().to(device).requires_grad_(True)
            x_bc1_lbfgs = x_bc1.detach().clone().to(device).requires_grad_(True)
            
            total_loss, _, _, _ = compute_loss(model, x_coll_lbfgs, x_bc0_lbfgs, x_bc1_lbfgs, loss_weights)
            total_loss.backward()
            return total_loss
        
        # L-BFGS optimizer
        optimizer_lbfgs = torch.optim.LBFGS(model.parameters(), 
                                           max_iter=20,
                                           line_search_fn='strong_wolfe')
        
        # Calculate the threshold for when to start tracking best model (80% of iterations)
        start_tracking_iter = int(patience_lbfgs * 0.8)
        
        # Run L-BFGS optimization with progress bar and early stopping
        with tqdm(total=patience_lbfgs, desc="L-BFGS optimization") as pbar:
            for i in range(patience_lbfgs):
                # Get current loss
                current_loss = optimizer_lbfgs.step(closure).item()
                
                # Only start tracking best model after 80% of iterations
                if i >= start_tracking_iter and current_loss < best_loss_lbfgs:
                    best_loss_lbfgs = current_loss
                    best_model_state_lbfgs = model.state_dict().copy()
                    print(f"New best L-BFGS model saved at iteration {i+1} with loss: {best_loss_lbfgs:.2e}")
                    patience_counter_lbfgs = 0
                elif i < start_tracking_iter:
                    # During initial iterations, just update best loss without saving model
                    if current_loss < best_loss_lbfgs:
                        best_loss_lbfgs = current_loss
                        patience_counter_lbfgs = 0
                else:
                    patience_counter_lbfgs += 1
                
                # Update progress bar
                pbar.set_postfix({
                    'loss': f"{current_loss:.2e}",
                    'best_loss': f"{best_loss_lbfgs:.2e}",
                    'counter': f"{patience_counter_lbfgs}/{patience_lbfgs}",
                    'tracking': f"{i >= start_tracking_iter}"
                })
                pbar.update(1)
                
                # Check if we should stop
                if patience_counter_lbfgs >= patience_lbfgs:
                    print(f"L-BFGS early stopping triggered after {i+1} iterations.")
                    break
            
            # Only restore the best model at the end of training
            if best_model_state_lbfgs is not None:
                model.load_state_dict(best_model_state_lbfgs)
                print(f"Restored best L-BFGS model with loss: {best_loss_lbfgs:.2e}")
            
        lbfgs_time = time.time() - lbfgs_start_time
        print(f"L-BFGS completed in {lbfgs_time:.2f} seconds")
        
        # Final evaluation
        model.eval()  # Set model to evaluation mode
        with torch.set_grad_enabled(True):
            # Make sure all inputs have requires_grad=True
            x_coll_eval = x_coll_all.detach().clone().requires_grad_(True)
            x_bc0_eval = x_bc0.detach().clone().requires_grad_(True)
            x_bc1_eval = x_bc1.detach().clone().requires_grad_(True)
            
            final_total_loss, final_pde_loss, final_bc_loss, final_grad_penalty = compute_loss(
                model, x_coll_eval, x_bc0_eval, x_bc1_eval, loss_weights)
        model.train()  # Set model back to training mode
        
        # print(f"After L-BFGS | Total Loss: {final_total_loss.item():.2e} | PDE: {final_pde_loss.item():.2e} | "
        #       f"BC: {final_bc_loss.item():.2e} | Grad: {final_grad_penalty.item():.2e} | E: {model.E.item():.4f}")
    
    # Create plots directory if it doesn't exist
    plots_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "efc_plots")
    if not os.path.exists(plots_dir):
        os.makedirs(plots_dir)
    
    # Save the model in the plots directory
    model_filename = os.path.join(plots_dir, f"pinn_seed{seed}_layers{layers}_neurons{neurons}.pth")
    torch.save(model.state_dict(), model_filename)
    
    # Plot training progress
    plt.figure(figsize=(12, 8))
    
    # Plot loss vs epochs
    plt.subplot(2, 1, 1)
    plt.semilogy(epochs, train_losses, 'b-')
    plt.xlabel('Epochs')
    plt.ylabel('Loss (log scale)')
    plt.title('Training Loss vs Epochs')
    plt.grid(True)
    
    # Plot loss vs time
    plt.subplot(2, 1, 2)
    plt.semilogy(times, train_losses, 'r-')
    plt.xlabel('Time (seconds)')
    plt.ylabel('Loss (log scale)')
    plt.title('Training Loss vs Time')
    plt.grid(True)
    
    plt.tight_layout()
    plt.savefig(os.path.join(plots_dir, f"training_progress_seed{seed}_layers{layers}_neurons{neurons}.png"))
    plt.close()
    
    # Calculate total training time
    total_time = time.time() - start_time
    print(f"Total training time: {total_time:.2f} seconds ({total_time/60:.2f} minutes)")
    
    return model, history

def plot_solutions_with_numerical(model, x_range=None, numerical_df=None, save_dir=None):
    model.eval()

    if x_range is None:
        x_range = torch.linspace(0.0, 1.0, 1000).reshape(-1, 1)
    
    # Move input to device
    x_range = x_range.to(device)

    with torch.no_grad():
        outputs = model(x_range)
        u, L, e, tau_xx, tau_yy, tau_zz = torch.split(outputs, 1, dim=1)

        # Move tensors to CPU before converting to numpy
        x_np = x_range.cpu().numpy().flatten()
        u_np = u.cpu().numpy().flatten()
        L_np = L.cpu().numpy().flatten()
        e_np = e.cpu().numpy().flatten()
        tau_xx_np = tau_xx.cpu().numpy().flatten()
        tau_yy_np = tau_yy.cpu().numpy().flatten()
        tau_zz_np = tau_zz.cpu().numpy().flatten()

    # Extract numerical data (correcting swapped columns)
    x_numerical = numerical_df["x"].values
    u_numerical = numerical_df["u"].values
    L_numerical = numerical_df["L"].values
    e_numerical = numerical_df["e"].values
    tau_xx_numerical = numerical_df["tau_xx"].values
    tau_yy_numerical = numerical_df["tau_zz"].values  # swapped intentionally
    tau_zz_numerical = numerical_df["tau_yy"].values  # swapped intentionally

    # Interpolate PINN predictions at numerical x locations
    u_interp = interp1d(x_np, u_np)(x_numerical)
    L_interp = interp1d(x_np, L_np)(x_numerical)
    e_interp = interp1d(x_np, e_np)(x_numerical)
    tau_xx_interp = interp1d(x_np, tau_xx_np)(x_numerical)
    tau_yy_interp = interp1d(x_np, tau_yy_np)(x_numerical)
    tau_zz_interp = interp1d(x_np, tau_zz_np)(x_numerical)

    # R² scores
    r2_scores = {
        'u': r2_score(u_numerical, u_interp),
        'L': r2_score(L_numerical, L_interp),
        'e': r2_score(e_numerical, e_interp),
        'tau_xx': r2_score(tau_xx_numerical, tau_xx_interp),
        'tau_yy': r2_score(tau_yy_numerical, tau_yy_interp),
        'tau_zz': r2_score(tau_zz_numerical, tau_zz_interp),
    }

    # Relative L² errors
    l2_errors = {
        'u': np.linalg.norm(u_numerical - u_interp) / np.linalg.norm(u_numerical),
        'L': np.linalg.norm(L_numerical - L_interp) / np.linalg.norm(L_numerical),
        'e': np.linalg.norm(e_numerical - e_interp) / np.linalg.norm(e_numerical),
        'tau_xx': np.linalg.norm(tau_xx_numerical - tau_xx_interp) / np.linalg.norm(tau_xx_numerical),
        'tau_yy': np.linalg.norm(tau_yy_numerical - tau_yy_interp) / np.linalg.norm(tau_yy_numerical),
        'tau_zz': np.linalg.norm(tau_zz_numerical - tau_zz_interp) / np.linalg.norm(tau_zz_numerical),
    }

    # Print results
    print("R² scores:")
    for var, score in r2_scores.items():
        print(f"{var}: {score:.6f}")

    print("\nRelative L² errors:")
    for var, error in l2_errors.items():
        print(f"{var}: {error:.6e}")

    # Total R² (optional)
    all_preds = np.concatenate([u_interp, L_interp, e_interp, tau_xx_interp, tau_yy_interp, tau_zz_interp])
    all_truth = np.concatenate([u_numerical, L_numerical, e_numerical, tau_xx_numerical, tau_yy_numerical, tau_zz_numerical])
    total_r2 = r2_score(all_truth, all_preds)
    print(f"\nTotal R² across all variables: {total_r2:.6f}")

    # Plotting
    fig, axs = plt.subplots(3, 2, figsize=(12, 15))
    fig.suptitle('PINN Solutions vs Numerical Solutions', fontsize=16)

    axs[0, 0].plot(x_np, u_np, 'b-', label='PINN u(x)')
    axs[0, 0].scatter(x_numerical, u_numerical, color='b', s=10, label='Numerical u(x)')
    axs[0, 0].set_xlabel('x'); axs[0, 0].set_ylabel('u'); axs[0, 0].legend(); axs[0, 0].grid(True)

    axs[0, 1].plot(x_np, L_np, 'r-', label='PINN L(x)')
    axs[0, 1].scatter(x_numerical, L_numerical, color='r', s=10, label='Numerical L(x)')
    axs[0, 1].set_xlabel('x'); axs[0, 1].set_ylabel('L'); axs[0, 1].legend(); axs[0, 1].grid(True)

    axs[1, 0].plot(x_np, e_np, 'g-', label='PINN ε(x)')
    axs[1, 0].scatter(x_numerical, e_numerical, color='g', s=10, label='Numerical ε(x)')
    axs[1, 0].set_xlabel('x'); axs[1, 0].set_ylabel('ε'); axs[1, 0].legend(); axs[1, 0].grid(True)

    axs[1, 1].plot(x_np, tau_xx_np, 'm-', label=r'PINN $\tau_{xx}(x)$')
    axs[1, 1].scatter(x_numerical, tau_xx_numerical, color='m', s=10, label=r'Numerical $\tau_{xx}(x)$')
    axs[1, 1].set_xlabel('x'); axs[1, 1].set_ylabel(r'$\tau_{xx}$'); axs[1, 1].legend(); axs[1, 1].grid(True)

    axs[2, 0].plot(x_np, tau_yy_np, 'c-', label=r'PINN $\tau_{yy}(x)$')
    axs[2, 0].scatter(x_numerical, tau_yy_numerical, color='c', s=10, label=r'Numerical $\tau_{yy}(x)$')
    axs[2, 0].set_xlabel('x'); axs[2, 0].set_ylabel(r'$\tau_{yy}$'); axs[2, 0].legend(); axs[2, 0].grid(True)

    axs[2, 1].plot(x_np, tau_zz_np, 'k-', label=r'PINN $\tau_{zz}(x)$')
    axs[2, 1].scatter(x_numerical, tau_zz_numerical, color='k', s=10, label=r'Numerical $\tau_{zz}(x)$')
    axs[2, 1].set_xlabel('x'); axs[2, 1].set_ylabel(r'$\tau_{zz}$'); axs[2, 1].legend(); axs[2, 1].grid(True)

    plt.tight_layout()
    plt.subplots_adjust(top=0.92)
    
    # Save the figure to the specified directory
    plt.savefig(os.path.join(save_dir, f"comparison_with_numerical_E{model.E.item():.4f}.png"))
    # Close the figure instead of showing it to avoid pop-up windows
    plt.close()

# Uncertainty quantification function
def run_uncertainty_quantification(num_runs=5, file_path=None, plot_average=False):
    # Create plots directory if it doesn't exist
    plots_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "efc_plots")
    if not os.path.exists(plots_dir):
        os.makedirs(plots_dir)
    
    # Create a subdirectory for uncertainty quantification results
    uq_dir = os.path.join(plots_dir, "uncertainty_quantification")
    if not os.path.exists(uq_dir):
        os.makedirs(uq_dir)
    
    if file_path is None:
        # Look for numerical data in the same directory as this script
        file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "efc_numerical.csv")
        if not os.path.exists(file_path):
            # Fallback to other locations
            file_path = os.path.join(os.getcwd(), "efc_numerical.csv")
            if not os.path.exists(file_path):
                file_path = os.path.join(os.getcwd(), "Downloads\\efc_numerical.csv")
    
    try:
        df = pd.read_csv(file_path)
    except FileNotFoundError:
        print(f"Warning: Could not find numerical data file at {file_path}")
        print("Proceeding without numerical comparison.")
        df = None
    
    # Lists to store metrics across runs
    E_values = []
    r2_scores_all = []
    l2_errors_all = []
    models = []  # Store models for later plotting
    
    # Training Works for 4567, 1234, 5678, 6789, 7890, 8901, 9012, 1111(plots not good)
    # Different seeds for uncertainty quantification
    seeds = [1234, 3456, 4567, 5678, 6789]
    
    # Create progress bar for all runs
    with tqdm(total=num_runs, desc="Uncertainty quantification") as pbar:
        # Run training multiple times with different seeds
        for i, seed in enumerate(seeds[:num_runs]):
            pbar.set_description(f"Run {i+1}/{num_runs} with seed {seed}")
            
            # Use best weights for training
            best_weights = {'pde': 1.0, 'bc': 0.1, 'grad': 0.001}  # Best weights from previous experiments
            model, _ = train_model(seed=seed, max_epochs=10000, loss_weights=best_weights)  
            models.append(model)  # Store model for later use
            
            # Get metrics if numerical data is available
            if df is not None:
                metrics = evaluate_model(model, df)
                E_values.append(model.E.item())
                r2_scores_all.append(metrics['r2_scores'])
                l2_errors_all.append(metrics['l2_errors'])
                
                # Generate and save plots for this run
                print(f"\nGenerating plots for run {i+1} (seed {seed})...")
                plot_solutions_with_numerical(model, numerical_df=df, save_dir=uq_dir)
                plt.close()  # Close the figure to avoid memory issues
                
                # Rename the saved file to include run number, seed, and timestamp
                import datetime
                timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                old_filename = os.path.join(uq_dir, f"comparison_with_numerical_E{model.E.item():.4f}.png")
                new_filename = os.path.join(uq_dir, f"run_{i+1}_seed_{seed}_E{model.E.item():.4f}_{timestamp}.png")
                if os.path.exists(old_filename):
                    # Use shutil.copy2 instead of os.rename to avoid conflicts
                    import shutil
                    shutil.copy2(old_filename, new_filename)
                    os.remove(old_filename)
            
            # Update progress bar
            pbar.update(1)
    
    # Plot average PINN outputs across all runs
    if plot_average and df is not None and len(models) > 0:
        print("\nGenerating average plot across all runs...")
        
        # Create x range for predictions
        x_range = torch.linspace(0.0, 1.0, 1000).reshape(-1, 1).to(device)
        x_np = x_range.cpu().numpy().flatten()
        
        # Extract numerical data (with swapped columns)
        x_numerical = df["x"].values
        u_numerical = df["u"].values
        L_numerical = df["L"].values
        e_numerical = df["e"].values
        tau_xx_numerical = df["tau_xx"].values
        tau_yy_numerical = df["tau_zz"].values  # swapped intentionally
        tau_zz_numerical = df["tau_yy"].values  # swapped intentionally
        
        # Initialize arrays to store predictions from all models
        all_u = []
        all_L = []
        all_e = []
        all_tau_xx = []
        all_tau_yy = []
        all_tau_zz = []
        
        # Get predictions from each model
        for model in models:
            model.eval()
            with torch.no_grad():
                outputs = model(x_range)
                u, L, e, tau_xx, tau_yy, tau_zz = torch.split(outputs, 1, dim=1)
                
                # Add to lists
                all_u.append(u.cpu().numpy().flatten())
                all_L.append(L.cpu().numpy().flatten())
                all_e.append(e.cpu().numpy().flatten())
                all_tau_xx.append(tau_xx.cpu().numpy().flatten())
                all_tau_yy.append(tau_yy.cpu().numpy().flatten())
                all_tau_zz.append(tau_zz.cpu().numpy().flatten())
        
        # Calculate averages
        avg_u = np.mean(all_u, axis=0)
        avg_L = np.mean(all_L, axis=0)
        avg_e = np.mean(all_e, axis=0)
        avg_tau_xx = np.mean(all_tau_xx, axis=0)
        avg_tau_yy = np.mean(all_tau_yy, axis=0)
        avg_tau_zz = np.mean(all_tau_zz, axis=0)
        
        # Calculate standard deviations for error bands
        std_u = np.std(all_u, axis=0)
        std_L = np.std(all_L, axis=0)
        std_e = np.std(all_e, axis=0)
        std_tau_xx = np.std(all_tau_xx, axis=0)
        std_tau_yy = np.std(all_tau_yy, axis=0)
        std_tau_zz = np.std(all_tau_zz, axis=0)
        
        # Interpolate average predictions at numerical x locations
        avg_u_interp = interp1d(x_np, avg_u, bounds_error=False, fill_value=(avg_u[0], avg_u[-1]))(x_numerical)
        avg_L_interp = interp1d(x_np, avg_L, bounds_error=False, fill_value=(avg_L[0], avg_L[-1]))(x_numerical)
        avg_e_interp = interp1d(x_np, avg_e, bounds_error=False, fill_value=(avg_e[0], avg_e[-1]))(x_numerical)
        avg_tau_xx_interp = interp1d(x_np, avg_tau_xx, bounds_error=False, fill_value=(avg_tau_xx[0], avg_tau_xx[-1]))(x_numerical)
        avg_tau_yy_interp = interp1d(x_np, avg_tau_yy, bounds_error=False, fill_value=(avg_tau_yy[0], avg_tau_yy[-1]))(x_numerical)
        avg_tau_zz_interp = interp1d(x_np, avg_tau_zz, bounds_error=False, fill_value=(avg_tau_zz[0], avg_tau_zz[-1]))(x_numerical)
        
        # Calculate R² scores for average predictions
        avg_r2_scores = {
            'u': r2_score(u_numerical, avg_u_interp),
            'L': r2_score(L_numerical, avg_L_interp),
            'e': r2_score(e_numerical, avg_e_interp),
            'tau_xx': r2_score(tau_xx_numerical, avg_tau_xx_interp),
            'tau_yy': r2_score(tau_yy_numerical, avg_tau_yy_interp),
            'tau_zz': r2_score(tau_zz_numerical, avg_tau_zz_interp),
        }
        
        # Calculate relative L² errors for average predictions
        avg_l2_errors = {
            'u': np.linalg.norm(u_numerical - avg_u_interp) / np.linalg.norm(u_numerical),
            'L': np.linalg.norm(L_numerical - avg_L_interp) / np.linalg.norm(L_numerical),
            'e': np.linalg.norm(e_numerical - avg_e_interp) / np.linalg.norm(e_numerical),
            'tau_xx': np.linalg.norm(tau_xx_numerical - avg_tau_xx_interp) / np.linalg.norm(tau_xx_numerical),
            'tau_yy': np.linalg.norm(tau_yy_numerical - avg_tau_yy_interp) / np.linalg.norm(tau_yy_numerical),
            'tau_zz': np.linalg.norm(tau_zz_numerical - avg_tau_zz_interp) / np.linalg.norm(tau_zz_numerical),
        }
        
        # Print results for average predictions
        print("\nR² scores for average predictions:")
        for var, score in avg_r2_scores.items():
            print(f"{var}: {score:.6f}")
        
        print("\nRelative L² errors for average predictions:")
        for var, error in avg_l2_errors.items():
            print(f"{var}: {error:.6e}")
        
        # Total R² for average predictions
        all_avg_preds = np.concatenate([avg_u_interp, avg_L_interp, avg_e_interp, avg_tau_xx_interp, avg_tau_yy_interp, avg_tau_zz_interp])
        all_truth = np.concatenate([u_numerical, L_numerical, e_numerical, tau_xx_numerical, tau_yy_numerical, tau_zz_numerical])
        avg_total_r2 = r2_score(all_truth, all_avg_preds)
        print(f"\nTotal R² for average predictions: {avg_total_r2:.6f}")
        
        # Create plot with average predictions and error bands
        fig, axs = plt.subplots(3, 2, figsize=(12, 15))
        fig.suptitle('Average PINN Solutions vs Numerical Solutions', fontsize=16)
        
        # Plot u
        axs[0, 0].plot(x_np, avg_u, 'b-', label='Avg PINN u(x)')
        axs[0, 0].fill_between(x_np, avg_u - std_u, avg_u + std_u, color='b', alpha=0.2, label='±1σ')
        axs[0, 0].scatter(x_numerical, u_numerical, color='r', s=10, label='Numerical u(x)')
        axs[0, 0].set_xlabel('x'); axs[0, 0].set_ylabel('u'); axs[0, 0].legend(); axs[0, 0].grid(True)
        
        # Plot L
        axs[0, 1].plot(x_np, avg_L, 'b-', label='Avg PINN L(x)')
        axs[0, 1].fill_between(x_np, avg_L - std_L, avg_L + std_L, color='b', alpha=0.2, label='±1σ')
        axs[0, 1].scatter(x_numerical, L_numerical, color='r', s=10, label='Numerical L(x)')
        axs[0, 1].set_xlabel('x'); axs[0, 1].set_ylabel('L'); axs[0, 1].legend(); axs[0, 1].grid(True)
        
        # Plot e
        axs[1, 0].plot(x_np, avg_e, 'b-', label='Avg PINN ε(x)')
        axs[1, 0].fill_between(x_np, avg_e - std_e, avg_e + std_e, color='b', alpha=0.2, label='±1σ')
        axs[1, 0].scatter(x_numerical, e_numerical, color='r', s=10, label='Numerical ε(x)')
        axs[1, 0].set_xlabel('x'); axs[1, 0].set_ylabel('ε'); axs[1, 0].legend(); axs[1, 0].grid(True)
        
        # Plot tau_xx
        axs[1, 1].plot(x_np, avg_tau_xx, 'b-', label=r'Avg PINN $\tau_{xx}(x)$')
        axs[1, 1].fill_between(x_np, avg_tau_xx - std_tau_xx, avg_tau_xx + std_tau_xx, color='b', alpha=0.2, label='±1σ')
        axs[1, 1].scatter(x_numerical, tau_xx_numerical, color='r', s=10, label=r'Numerical $\tau_{xx}(x)$')
        axs[1, 1].set_xlabel('x'); axs[1, 1].set_ylabel(r'$\tau_{xx}$'); axs[1, 1].legend(); axs[1, 1].grid(True)
        
        # Plot tau_yy
        axs[2, 0].plot(x_np, avg_tau_yy, 'b-', label=r'Avg PINN $\tau_{yy}(x)$')
        axs[2, 0].fill_between(x_np, avg_tau_yy - std_tau_yy, avg_tau_yy + std_tau_yy, color='b', alpha=0.2, label='±1σ')
        axs[2, 0].scatter(x_numerical, tau_yy_numerical, color='r', s=10, label=r'Numerical $\tau_{yy}(x)$')
        axs[2, 0].set_xlabel('x'); axs[2, 0].set_ylabel(r'$\tau_{yy}$'); axs[2, 0].legend(); axs[2, 0].grid(True)
        
        # Plot tau_zz
        axs[2, 1].plot(x_np, avg_tau_zz, 'b-', label=r'Avg PINN $\tau_{zz}(x)$')
        axs[2, 1].fill_between(x_np, avg_tau_zz - std_tau_zz, avg_tau_zz + std_tau_zz, color='b', alpha=0.2, label='±1σ')
        axs[2, 1].scatter(x_numerical, tau_zz_numerical, color='r', s=10, label=r'Numerical $\tau_{zz}(x)$')
        axs[2, 1].set_xlabel('x'); axs[2, 1].set_ylabel(r'$\tau_{zz}$'); axs[2, 1].legend(); axs[2, 1].grid(True)
        
        plt.tight_layout()
        plt.subplots_adjust(top=0.92)
        
        # Save the plot
        avg_plot_filename = os.path.join(uq_dir, f"average_predictions_across_{num_runs}_runs.png")
        plt.savefig(avg_plot_filename, dpi=300, bbox_inches='tight')
        print(f"Saved average plot to {avg_plot_filename}")
        plt.close()
    
    # Calculate statistics across runs
    if df is not None and len(E_values) > 0:
        # Convert to numpy arrays for easier statistics
        E_array = np.array(E_values)
        
        # Initialize dictionaries for R² and L² statistics
        r2_mean = {}
        r2_std = {}
        l2_mean = {}
        l2_std = {}
        
        # Calculate statistics for each variable
        variables = ['u', 'L', 'e', 'tau_xx', 'tau_yy', 'tau_zz']
        for var in variables:
            r2_values = np.array([run[var] for run in r2_scores_all])
            l2_values = np.array([run[var] for run in l2_errors_all])
            
            r2_mean[var] = np.mean(r2_values)
            r2_std[var] = np.std(r2_values)
            l2_mean[var] = np.mean(l2_values)
            l2_std[var] = np.std(l2_values)
        
        # Print statistics
        print("\n===== Uncertainty Quantification Results =====")
        print(f"E value: {np.mean(E_array):.4f} ± {np.std(E_array):.4f}")
        
        print("\nR² scores (mean ± std):")
        for var in variables:
            print(f"{var}: {r2_mean[var]:.6f} ± {r2_std[var]:.6f}")
        
        print("\nRelative L² errors (mean ± std):")
        for var in variables:
            print(f"{var}: {l2_mean[var]:.6e} ± {l2_std[var]:.6e}")
        
        # Calculate total R² statistics
        total_r2_values = []
        for i in range(len(r2_scores_all)):
            all_vars_r2 = np.mean([r2_scores_all[i][var] for var in variables])
            total_r2_values.append(all_vars_r2)
        
        total_r2_array = np.array(total_r2_values)
        print(f"\nTotal R² across all variables: {np.mean(total_r2_array):.6f} ± {np.std(total_r2_array):.6f}")
        
        # Save R² scores to CSV
        r2_df = pd.DataFrame()
        r2_df['Run'] = range(1, len(r2_scores_all) + 1)
        r2_df['Seed'] = seeds[:len(r2_scores_all)]
        r2_df['E'] = E_values
        
        for var in variables:
            r2_df[f'R2_{var}'] = [run[var] for run in r2_scores_all]
            r2_df[f'L2_{var}'] = [run[var] for run in l2_errors_all]
        
        r2_df['Total_R2'] = total_r2_values
        
        # Save to CSV
        csv_path = os.path.join(uq_dir, "uncertainty_quantification_results.csv")
        r2_df.to_csv(csv_path, index=False)
        print(f"\nSaved R² scores to {csv_path}")
        
        # Create a summary plot of R² scores across runs
        plt.figure(figsize=(12, 8))
        
        # Plot R² for each variable across runs
        for i, var in enumerate(variables):
            plt.subplot(3, 2, i+1)
            var_r2 = [run[var] for run in r2_scores_all]
            plt.bar(range(1, len(var_r2) + 1), var_r2)
            plt.axhline(y=r2_mean[var], color='r', linestyle='-', label=f'Mean: {r2_mean[var]:.4f}')
            plt.axhline(y=r2_mean[var] + r2_std[var], color='r', linestyle='--', alpha=0.5)
            plt.axhline(y=r2_mean[var] - r2_std[var], color='r', linestyle='--', alpha=0.5)
            plt.xlabel('Run')
            plt.ylabel(f'R² for {var}')
            plt.title(f'R² for {var} across runs')
            plt.legend()
            plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(os.path.join(uq_dir, "r2_scores_across_runs.png"))
        plt.close()
        
        # Create a summary plot of total R² across runs
        plt.figure(figsize=(10, 6))
        plt.bar(range(1, len(total_r2_values) + 1), total_r2_values)
        plt.axhline(y=np.mean(total_r2_array), color='r', linestyle='-', 
                   label=f'Mean: {np.mean(total_r2_array):.4f} ± {np.std(total_r2_array):.4f}')
        plt.axhline(y=np.mean(total_r2_array) + np.std(total_r2_array), color='r', linestyle='--', alpha=0.5)
        plt.axhline(y=np.mean(total_r2_array) - np.std(total_r2_array), color='r', linestyle='--', alpha=0.5)
        plt.xlabel('Run')
        plt.ylabel('Total R² (average across all variables)')
        plt.title('Total R² across runs')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.savefig(os.path.join(uq_dir, "total_r2_across_runs.png"))
        plt.close()
        
        return {
            'E': (np.mean(E_array), np.std(E_array)),
            'r2_mean': r2_mean,
            'r2_std': r2_std,
            'l2_mean': l2_mean,
            'l2_std': l2_std,
            'models': models,  # Return models for further analysis if needed
            'r2_scores_all': r2_scores_all,  # Return all R² scores
            'csv_path': csv_path  # Path to the saved CSV file
        }
    
    return None

# Function to evaluate model metrics
def evaluate_model(model, numerical_df):
    try:
        # Extract numerical data (with swapped columns to match plot_solutions_with_numerical)
        x_numerical = numerical_df["x"].values
        u_numerical = numerical_df["u"].values
        L_numerical = numerical_df["L"].values
        e_numerical = numerical_df["e"].values
        tau_xx_numerical = numerical_df["tau_xx"].values
        tau_yy_numerical = numerical_df["tau_zz"].values  # swapped intentionally to match plot_solutions_with_numerical
        tau_zz_numerical = numerical_df["tau_yy"].values  # swapped intentionally to match plot_solutions_with_numerical
        
        # Get the device of the model
        device = next(model.parameters()).device
        
        # Generate PINN predictions - ensure we cover the full range of numerical data
        min_x = min(x_numerical)
        max_x = max(x_numerical)
        x = torch.linspace(min_x, max_x, 1000).reshape(-1, 1).to(device)
        
        with torch.no_grad():
            outputs = model(x)
        
        # Extract individual variables and move to CPU for numpy conversion
        u_np = outputs[:, 0].cpu().numpy()
        L_np = outputs[:, 1].cpu().numpy()
        e_np = outputs[:, 2].cpu().numpy()
        tau_xx_np = outputs[:, 3].cpu().numpy()
        tau_yy_np = outputs[:, 4].cpu().numpy()
        tau_zz_np = outputs[:, 5].cpu().numpy()
        x_np = x.cpu().numpy().flatten()
        
        # Interpolate PINN predictions at numerical x locations with bounds handling
        u_interp = interp1d(x_np, u_np, bounds_error=False, fill_value=(u_np[0], u_np[-1]))(x_numerical)
        L_interp = interp1d(x_np, L_np, bounds_error=False, fill_value=(L_np[0], L_np[-1]))(x_numerical)
        e_interp = interp1d(x_np, e_np, bounds_error=False, fill_value=(e_np[0], e_np[-1]))(x_numerical)
        tau_xx_interp = interp1d(x_np, tau_xx_np, bounds_error=False, fill_value=(tau_xx_np[0], tau_xx_np[-1]))(x_numerical)
        tau_yy_interp = interp1d(x_np, tau_yy_np, bounds_error=False, fill_value=(tau_yy_np[0], tau_yy_np[-1]))(x_numerical)
        tau_zz_interp = interp1d(x_np, tau_zz_np, bounds_error=False, fill_value=(tau_zz_np[0], tau_zz_np[-1]))(x_numerical)
        
        # R² scores
        r2_scores = {
            'u': r2_score(u_numerical, u_interp),
            'L': r2_score(L_numerical, L_interp),
            'e': r2_score(e_numerical, e_interp),
            'tau_xx': r2_score(tau_xx_numerical, tau_xx_interp),
            'tau_yy': r2_score(tau_yy_numerical, tau_yy_interp),
            'tau_zz': r2_score(tau_zz_numerical, tau_zz_interp),
        }
    except Exception as e:
        print(f"Error in evaluate_model: {e}")
        return None
    
    # Relative L² errors
    l2_errors = {
        'u': np.linalg.norm(u_numerical - u_interp) / np.linalg.norm(u_numerical),
        'L': np.linalg.norm(L_numerical - L_interp) / np.linalg.norm(L_numerical),
        'e': np.linalg.norm(e_numerical - e_interp) / np.linalg.norm(e_numerical),
        'tau_xx': np.linalg.norm(tau_xx_numerical - tau_xx_interp) / np.linalg.norm(tau_xx_numerical),
        'tau_yy': np.linalg.norm(tau_yy_numerical - tau_yy_interp) / np.linalg.norm(tau_yy_numerical),
        'tau_zz': np.linalg.norm(tau_zz_numerical - tau_zz_interp) / np.linalg.norm(tau_zz_numerical),
    }
    
    return {
        'r2_scores': r2_scores,
        'l2_errors': l2_errors
    }


# Example usage
if __name__ == "__main__":
    # Create plots directory if it doesn't exist
    plots_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "efc_plots")
    if not os.path.exists(plots_dir):
        os.makedirs(plots_dir)
        print(f"Created directory: {plots_dir}")
    
    # Look for numerical data in the same directory as this script
    file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "efc_numerical.csv")
    if not os.path.exists(file_path):
        # Fallback to other locations
        file_path = os.path.join(os.getcwd(), "efc_numerical.csv")
        if not os.path.exists(file_path):
            file_path = os.path.join(os.getcwd(), "Downloads\\efc_numerical.csv")
    
    # Uncomment one of the following options to run:
    
    # Option 1: Train a single model with default parameters
    best_weights = {'pde': 1.0, 'bc': 0.1, 'grad': 0.001}
    # model, _ = train_model(seed=1234, loss_weights=best_weights, patience_adam=1000, patience_lbfgs=5, max_epochs=10)
    
    # if os.path.exists(file_path):
    #     print(f"Found numerical data at: {file_path}")
    #     df = pd.read_csv(file_path)
    #     plot_solutions_with_numerical(model, numerical_df=df, save_dir=plots_dir)
    # else:
    #     print(f"Warning: Could not find numerical data file. Plotting without comparison.")
    
    
    # Option 3: Run uncertainty quantification
    # uq_results = run_uncertainty_quantification(num_runs=5, plot_average=True)
    
